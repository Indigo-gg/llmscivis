# Mock Generation Pipeline å®ç°æ€»ç»“

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

å®Œæˆäº†æ¨¡æ‹Ÿå‰ç«¯é¡µé¢æ£€ç´¢åå®Œæ•´æµç¨‹çš„å®ç°ï¼ŒåŒ…æ‹¬ï¼š**æç¤ºè¯æ‹“å±• â†’ RAG æ£€ç´¢ â†’ ä»£ç ç”Ÿæˆ â†’ ä»£ç è¯„ä¼°**

æ‰€æœ‰åŠŸèƒ½å‡å¤ç”¨äº† `app.py` å’Œå…¶ä»–æ ¸å¿ƒæ¨¡å—çš„é€»è¾‘ï¼Œæ”¯æŒæ‰¹é‡å¤„ç† Excel æ–‡ä»¶ã€‚

## ğŸ¯ å®ç°å†…å®¹

### 1. **RAG æ£€ç´¢æ¨¡å—å¢å¼º** (`RAG/retriever_v3.py`)

#### æ–°å¢å‡½æ•°ï¼š`process_benchmark_prompts_for_generation()`

**åŠŸèƒ½**ï¼šä» Excel è¯»å– "Benchmark prompt" å­—æ®µï¼Œæ‰§è¡Œå®Œæ•´çš„æç¤ºè¯æ‹“å±•å’Œ RAG æ£€ç´¢æµç¨‹

**æ ¸å¿ƒå‚æ•°**ï¼š
```python
def process_benchmark_prompts_for_generation(
    input_file: str,                    # è¾“å…¥ Excel æ–‡ä»¶
    output_file: str = None,            # è¾“å‡ºæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    sheet_name: str = 'ç¬¬äºŒæœŸå®éªŒæ•°æ®'  # å·¥ä½œè¡¨åç§°
) -> dict
```

**å®ç°æ­¥éª¤**ï¼š
1. è¯»å– Excel ä¸­çš„ "Benchmark prompt" åˆ—
2. é€è¡Œæ‰§è¡Œæç¤ºè¯æ‹“å±• (`analyze_query()`)
3. åŸºäºæ‹“å±•ç»“æœæ‰§è¡Œ RAG æ£€ç´¢ (`VTKSearcherV3.search()`)
4. æå–æ£€ç´¢ç»“æœå…ƒæ•°æ®
5. å°†æ‰€æœ‰ä¸­é—´ç»“æœå†™å› Excel

**è¾“å‡ºåˆ—**ï¼š
- `analysis_result` - æ‹“å±•ç»“æœ (JSON)
- `final_prompt` - æœ€ç»ˆæç¤ºè¯
- `retrieval_time` - æ£€ç´¢è€—æ—¶
- `retrieval_results` - æ£€ç´¢ç»“æœå…ƒæ•°æ® (JSON)

**ä»£ç ä½ç½®**ï¼š[RAG/retriever_v3.py#L681-L825](RAG/retriever_v3.py)

---

### 2. **å®Œæ•´ç”Ÿæˆå’Œè¯„ä¼°ç®¡é“** (`test/mock_generation/mock_generation.py`)

#### æ ¸å¿ƒç±»ï¼š`MockGenerationPipeline`

**åŠŸèƒ½**ï¼šå®ç°å‰ç«¯é¡µé¢æ£€ç´¢åçš„å®Œæ•´æµç¨‹ï¼ˆç”Ÿæˆ + è¯„ä¼°ï¼‰

**æ ¸å¿ƒæ–¹æ³•**ï¼š
```python
class MockGenerationPipeline:
    def __init__(self, excel_path: str)
    def run_complete_pipeline(
        self,
        generator: str = 'deepseek-v3',
        evaluator: str = 'deepseek-v3'
    ) -> dict
```

**å¤„ç†æµç¨‹**ï¼š

```
[Step 1] ä» Excel è¯»å– & RAG æ£€ç´¢
â†“
è°ƒç”¨ process_benchmark_prompts_for_generation()
  â”œâ”€â”€ æç¤ºè¯æ‹“å±• (analyze_query)
  â”œâ”€â”€ RAG æ£€ç´¢ (RAGAgent.search)
  â””â”€â”€ ä¿å­˜ä¸­é—´ç»“æœåˆ° Excel
â†“
[Step 2] ä»£ç ç”Ÿæˆ
â†“
é€è¡Œè¯»å– Excelï¼Œè·å– final_prompt
  â”œâ”€â”€ è°ƒç”¨ LLM (get_llm_response)
  â”œâ”€â”€ ç”Ÿæˆ VTK.js ä»£ç 
  â””â”€â”€ ä¿å­˜ç”Ÿæˆçš„ä»£ç 
â†“
[Step 3] ä»£ç è¯„ä¼°
â†“
é€è¡Œæ‰§è¡Œè¯„ä¼°
  â”œâ”€â”€ è°ƒç”¨è¯„ä¼°å™¨ (evaluator_agent.evaluate)
  â”œâ”€â”€ è·å–è¯„ä¼°åˆ†æ•°
  â””â”€â”€ ä¿å­˜è¯„ä¼°ç»“æœ
â†“
[Output] ä¿å­˜æœ€ç»ˆç»“æœåˆ° *_output.xlsx
```

**å¤ç”¨çš„æ ¸å¿ƒå‡½æ•°**ï¼š

| åŠŸèƒ½ | æ¥æº | å¤ç”¨æ–¹å¼ |
|------|------|--------|
| æç¤ºè¯æ‹“å±• | `llm_agent/prompt_agent.py` | ç›´æ¥è°ƒç”¨ `analyze_query()` |
| RAG æ£€ç´¢ | `llm_agent/rag_agent.py` | åˆ›å»º `RAGAgent` å®ä¾‹ï¼Œè°ƒç”¨ `search()` |
| ä»£ç ç”Ÿæˆ | `llm_agent/ollma_chat.py` | ç›´æ¥è°ƒç”¨ `get_llm_response()` |
| ä»£ç è¯„ä¼° | `llm_agent/evaluator_agent.py` | ç›´æ¥è°ƒç”¨ `evaluate()` |

**ä»£ç ä½ç½®**ï¼š[test/mock_generation/mock_generation.py#L1-308](test/mock_generation/mock_generation.py)

---

### 3. **ä½¿ç”¨ç¤ºä¾‹å’Œæ–‡æ¡£**

#### ğŸ“„ æä¾›çš„æ–‡ä»¶

| æ–‡ä»¶ | æè¿° |
|------|------|
| [test/mock_generation/README.md](test/mock_generation/README.md) | è¯¦ç»†åŠŸèƒ½æ–‡æ¡£å’Œ API å‚è€ƒ |
| [test/mock_generation/test_example.py](test/mock_generation/test_example.py) | 4 ä¸ªå®Œæ•´ä½¿ç”¨ç¤ºä¾‹ |
| [MOCK_GENERATION_INTEGRATION.md](MOCK_GENERATION_INTEGRATION.md) | é›†æˆæŒ‡å—å’Œè¯¦ç»†è¯´æ˜ |
| [test_mock_generation_import.py](test_mock_generation_import.py) | å¯¼å…¥å’Œä¾èµ–éªŒè¯è„šæœ¬ |
| [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md) | æœ¬æ–‡ä»¶ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šå‘½ä»¤è¡Œæ‰§è¡Œ

```bash
cd d:\Pcode\LLM4VIS\llmscivis

# æ‰§è¡Œå®Œæ•´æµç¨‹ï¼ˆæ‹“å±• â†’ æ£€ç´¢ â†’ ç”Ÿæˆ â†’ è¯„ä¼°ï¼‰
python test/mock_generation/mock_generation.py \
    --excel experiment_results/retrieval_results_v3_output.xlsx \
    --generator deepseek-v3 \
    --evaluator deepseek-v3
```

### æ–¹å¼äºŒï¼šPython ä»£ç è°ƒç”¨

```python
from test.mock_generation.mock_generation import MockGenerationPipeline

# åˆ›å»ºç®¡é“
pipeline = MockGenerationPipeline('your_excel.xlsx')

# æ‰§è¡Œå®Œæ•´æµç¨‹
result = pipeline.run_complete_pipeline(
    generator='deepseek-v3',
    evaluator='deepseek-v3'
)

# æŸ¥çœ‹ç»“æœ
if result['success']:
    pipeline.print_results_summary()
    print(f"è¾“å‡ºæ–‡ä»¶: {result['output_file']}")
```

### æ–¹å¼ä¸‰ï¼šä»…æ‰§è¡Œæ£€ç´¢æ­¥éª¤

```python
from RAG.retriever_v3 import process_benchmark_prompts_for_generation

result = process_benchmark_prompts_for_generation(
    input_file='input.xlsx',
    output_file='output.xlsx'
)
```

---

## ğŸ“Š æ•°æ®æµç¤ºä¾‹

### è¾“å…¥ Excel æ ¼å¼

| Benchmark prompt | groundTruth | generatorPrompt | evaluatorPrompt |
|------------------|------------|-----------------|-----------------|
| render a cone with blue color | `<html>...</html>` | å¯é€‰ | å¯é€‰ |

### è¾“å‡º Excel æ ¼å¼

| ... | analysis_result | final_prompt | retrieval_time | ... | generated_code | generation_time | score |
|-----|-----------------|--------------|-----------------|-----|-----------------|------------------|-------|
| ... | `[{phase: ..., description: ...}]` (JSON) | `Generate only HTML...` | 0.45 | ... | `<html>...</html>` | 2.3 | 8.5 |

---

## ğŸ”„ ä¸ app.py çš„å…³ç³»

### é€»è¾‘å¯¹åº”

```
app.py (/generate ç«¯ç‚¹)
â”‚
â”œâ”€â”€ [æµç¨‹ 1] æç¤ºè¯æ‹“å±•
â”‚   â””â”€â”€ analyze_query()
â”‚
â”œâ”€â”€ [æµç¨‹ 2] RAG æ£€ç´¢
â”‚   â””â”€â”€ RAGAgent.search()
â”‚
â”œâ”€â”€ [æµç¨‹ 3] ä»£ç ç”Ÿæˆ
â”‚   â””â”€â”€ get_llm_response()
â”‚
â””â”€â”€ [æµç¨‹ 4] ä»£ç è¯„ä¼°
    â””â”€â”€ evaluator_agent.evaluate()

        â†“ (å¤ç”¨)

mock_generation.py (MockGenerationPipeline)
â”‚
â”œâ”€â”€ [Step 1] æ£€ç´¢é˜¶æ®µ
â”‚   â””â”€â”€ process_benchmark_prompts_for_generation()
â”‚       â”œâ”€â”€ analyze_query()
â”‚       â””â”€â”€ RAGAgent.search()
â”‚
â”œâ”€â”€ [Step 2] ç”Ÿæˆé˜¶æ®µ
â”‚   â””â”€â”€ get_llm_response()
â”‚
â””â”€â”€ [Step 3] è¯„ä¼°é˜¶æ®µ
    â””â”€â”€ evaluator_agent.evaluate()
```

### å…³é”®åŒºåˆ«

| ç»´åº¦ | app.py | mock_generation.py |
|------|--------|-----------------|
| **å·¥ä½œæ¨¡å¼** | REST API (å®æ—¶) | æ‰¹å¤„ç† (ç¦»çº¿) |
| **æ•°æ®æ¥æº** | å‰ç«¯ HTTP è¯·æ±‚ | Excel æ–‡ä»¶ |
| **å¤„ç†å¯¹è±¡** | å•ä¸ªæ¡ˆä¾‹ | å¤šä¸ªæ¡ˆä¾‹ |
| **ä½¿ç”¨åœºæ™¯** | ç”Ÿäº§ç¯å¢ƒ | å®éªŒ/æµ‹è¯• |
| **å¹¶å‘æ€§** | æ”¯æŒå¹¶å‘è¯·æ±‚ | é¡ºåºå¤„ç† |

---

## ğŸ“ æ–‡ä»¶æ¸…å•

### æ–°å¢æ–‡ä»¶

```
test/
â”œâ”€â”€ __init__.py                          [æ–°å¢] åŒ…åˆå§‹åŒ–
â”œâ”€â”€ mock_generation/
â”‚   â”œâ”€â”€ __init__.py                      [æ–°å¢] åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ mock_generation.py               [æ–°å¢] ä¸»æ¨¡å— (308 è¡Œ)
â”‚   â”œâ”€â”€ README.md                        [æ–°å¢] è¯¦ç»†æ–‡æ¡£ (211 è¡Œ)
â”‚   â””â”€â”€ test_example.py                  [æ–°å¢] ä½¿ç”¨ç¤ºä¾‹ (274 è¡Œ)
â”œâ”€â”€ (å…¶ä»–ç°å­˜æ–‡ä»¶)

MOCK_GENERATION_INTEGRATION.md           [æ–°å¢] é›†æˆæŒ‡å— (471 è¡Œ)
IMPLEMENTATION_SUMMARY.md                [æ–°å¢] æœ¬æ–‡ä»¶
test_mock_generation_import.py           [æ–°å¢] éªŒè¯è„šæœ¬ (152 è¡Œ)
```

### ä¿®æ”¹æ–‡ä»¶

```
RAG/
â””â”€â”€ retriever_v3.py                      [ä¿®æ”¹] +147 è¡Œæ–°å¢å‡½æ•°
```

---

## ğŸ”§ æ ¸å¿ƒå‡½æ•°ç­¾å

### process_benchmark_prompts_for_generation()

```python
def process_benchmark_prompts_for_generation(
    input_file: str,
    output_file: str = None,
    sheet_name: str = 'ç¬¬äºŒæœŸå®éªŒæ•°æ®'
) -> dict:
    """
    è¯»å– Excel ä¸­çš„ Benchmark promptï¼Œæ‰§è¡Œæç¤ºè¯æ‹“å±•å’Œæ£€ç´¢
    
    Returns:
    {
        'success': True/False,
        'total_rows': int,
        'processed': int,
        'errors': int,
        'output_file': str
    }
    """
```

### MockGenerationPipeline.run_complete_pipeline()

```python
def run_complete_pipeline(
    self,
    generator: str = 'deepseek-v3',
    evaluator: str = 'deepseek-v3'
) -> dict:
    """
    æ‰§è¡Œå®Œæ•´çš„ç”Ÿæˆå’Œè¯„ä¼°æµç¨‹
    
    Returns:
    {
        'success': True/False,
        'total_rows': int,
        'processed': int,
        'errors': int,
        'output_file': str,
        'results': [list of results]
    }
    """
```

---

## ğŸ“ˆ å¤„ç†ç»Ÿè®¡ç¤ºä¾‹

```
[Completed] å¤„ç†å®Œæˆ
  - æ€»è¡Œæ•°: 10
  - æˆåŠŸå¤„ç†: 9
  - å¤±è´¥: 1
  - è¾“å‡ºæ–‡ä»¶: experiment_results/retrieval_results_v3_output_output.xlsx
```

---

## âœ… éªŒè¯æ¸…å•

- âœ… `RAG/retriever_v3.py` ä¸­æ–°å¢ `process_benchmark_prompts_for_generation()` å‡½æ•°
- âœ… å®ç°äº†å®Œæ•´çš„æç¤ºè¯æ‹“å±• + æ£€ç´¢ + ç”Ÿæˆ + è¯„ä¼°æµç¨‹
- âœ… æ”¯æŒä» Excel è¯»å†™æ•°æ®
- âœ… å®Œå…¨å¤ç”¨äº† `app.py` å’Œå…¶ä»–æ ¸å¿ƒæ¨¡å—çš„é€»è¾‘
- âœ… æä¾›äº†è¯¦ç»†çš„æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
- âœ… åˆ›å»ºäº†éªŒè¯è„šæœ¬
- âœ… æ‰€æœ‰ Python ä»£ç é€šè¿‡è¯­æ³•æ£€æŸ¥

---

## ğŸ“š æ–‡æ¡£é“¾æ¥

### è¯¦ç»†æ–‡æ¡£

1. **[test/mock_generation/README.md](test/mock_generation/README.md)** - åŠŸèƒ½è¯¦è§£å’Œ API å‚è€ƒ
2. **[MOCK_GENERATION_INTEGRATION.md](MOCK_GENERATION_INTEGRATION.md)** - é›†æˆæŒ‡å—
3. **[test/mock_generation/test_example.py](test/mock_generation/test_example.py)** - 4 ä¸ªå®Œæ•´ç¤ºä¾‹

### ç›¸å…³æºæ–‡ä»¶

1. **[app.py](app.py)** - Flask åº”ç”¨ï¼ŒåŒ…å«åŸå§‹çš„ç”Ÿæˆ/è¯„ä¼°é€»è¾‘
2. **[llm_agent/prompt_agent.py](llm_agent/prompt_agent.py)** - æç¤ºè¯æ‹“å±•
3. **[llm_agent/rag_agent.py](llm_agent/rag_agent.py)** - RAG æ£€ç´¢
4. **[llm_agent/evaluator_agent.py](llm_agent/evaluator_agent.py)** - ä»£ç è¯„ä¼°
5. **[RAG/retriever_v3.py](RAG/retriever_v3.py)** - æ£€ç´¢å™¨ (æ–°å¢å‡½æ•°)

---

## ğŸ“ å…³é”®è®¾è®¡å†³ç­–

### 1. **å®Œå…¨å¤ç”¨ç°æœ‰é€»è¾‘**

- ç›´æ¥è°ƒç”¨ `app.py` ä¸­çš„å‡½æ•°ï¼Œé¿å…ä»£ç é‡å¤
- ä¿æŒä¸ç”Ÿäº§ç¯å¢ƒä¸€è‡´çš„è¡Œä¸º

### 2. **æ”¯æŒçµæ´»çš„å‚æ•°é…ç½®**

- å¯æŒ‡å®šä¸åŒçš„ç”Ÿæˆå™¨å’Œè¯„ä¼°å™¨æ¨¡å‹
- æ”¯æŒè‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯

### 3. **å®Œæ•´çš„é”™è¯¯å¤„ç†**

- å•è¡Œé”™è¯¯ä¸å½±å“å…¶ä»–è¡Œå¤„ç†
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—å’Œç»Ÿè®¡

### 4. **ä¸­é—´ç»“æœä¿å­˜**

- æ¯ä¸ªæ­¥éª¤çš„ç»“æœéƒ½ä¿å­˜åˆ° Excel
- ä¾¿äºè°ƒè¯•å’Œåˆ†æ

---

## ğŸ” ä¾èµ–å…³ç³»

```
mock_generation.py
â”œâ”€â”€ RAG/retriever_v3.py
â”‚   â”œâ”€â”€ llm_agent/prompt_agent.py (analyze_query)
â”‚   â”œâ”€â”€ config/ollama_config.py
â”‚   â””â”€â”€ RAG/vtk_code_meta_extract.py
â”œâ”€â”€ llm_agent/rag_agent.py (RAGAgent)
â”œâ”€â”€ llm_agent/ollma_chat.py (get_llm_response)
â”œâ”€â”€ llm_agent/evaluator_agent.py (evaluate)
â”œâ”€â”€ pandas (Excel è¯»å†™)
â””â”€â”€ openpyxl (Excel å¼•æ“)
```

---

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **MongoDB ä¾èµ–** - RAG æ£€ç´¢éœ€è¦ MongoDB æœåŠ¡è¿è¡Œ
2. **æ¨¡å‹é…ç½®** - åœ¨ `config/ollama_config.py` ä¸­é…ç½®å¯ç”¨æ¨¡å‹
3. **ç½‘ç»œè¿æ¥** - è°ƒç”¨è¿œç¨‹ LLM API éœ€è¦ç½‘ç»œè¿æ¥
4. **æ€§èƒ½** - å¤§è§„æ¨¡æ•°æ®å¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´

---

## ğŸ“ æ”¯æŒ

è¯¦è§ä»¥ä¸‹æ–‡æ¡£è·å–æ›´å¤šå¸®åŠ©ï¼š

- åŠŸèƒ½é—®é¢˜ï¼š[test/mock_generation/README.md](test/mock_generation/README.md#å¸¸è§é—®é¢˜)
- é›†æˆé—®é¢˜ï¼š[MOCK_GENERATION_INTEGRATION.md](MOCK_GENERATION_INTEGRATION.md#æ•…éšœæ’é™¤)
- ä½¿ç”¨ç¤ºä¾‹ï¼š[test/mock_generation/test_example.py](test/mock_generation/test_example.py)

---

**å®ç°å®Œæˆæ—¶é—´**ï¼š2025-12-08

**æ ¸å¿ƒä»£ç **ï¼š
- `RAG/retriever_v3.py` - 147 è¡Œæ–°å¢å‡½æ•°
- `test/mock_generation/mock_generation.py` - 308 è¡Œä¸»æ¨¡å—
- **æ€»è®¡æ–°å¢ä»£ç **ï¼šçº¦ 800+ è¡Œï¼ˆå«æ–‡æ¡£å’Œç¤ºä¾‹ï¼‰

